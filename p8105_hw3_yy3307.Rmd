---
title: "p8105_hw3_yy3307"
output: github_document
date: "2022-10-07"
author: "Yang Yi"
UNI: "yy3307"
---

```{r setup, include = FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1
The first step we need to do is importing the `instacart` data from `p8105.datasets`.
```{r import instacart}
data("instacart")

instacart = 
  instacart %>% 
  as_tibble(instacart)
```

_The `Instacart` dataset contains data of online grovery services which allow peopleto shop online from local stores. The dataset has `r nrow(instacart)` rows and `r ncol(instacart)` columns, which includes variables of `order_id, product_id, add_to_cart_order, reordered, user_id, eval_set, order_number, order_dow, order_hour_of_day, days_since_prior_order, product_name, aisle_id, department_id, aisle, department`. We can make some data analysis with this dataset, for instance, we can indicate which type of grocery is most popular by counting frequencies of `aisle` variable. Also, we can observe something like the `reorder rate`, the `reorder rate` of this dataset is `r colMeans(instacart[c("reordered")])`, which means that about 59.86% of all customers would like to reorder._

We can use `count` and `distinct` functions to find the total number of aisles. And we also need to return the `name` of aisle which most repeated being ordered, `which.max` can help us find that aisle. The most occurrence aisle is easy to find, but we need to `filter` the aisle column to eliminate the most occurrence aisle first and again use `which.max` to find the second most occurrence aisle from the new list of aisles.

```{r aisles}
num_aisle = count(distinct(instacart, aisle))

aisle_most = names(which.max(table(instacart$aisle)))

except_fresh =
  instacart %>%
  filter(!grepl('fresh vegetables', aisle))
aisle_2most = names(which.max(table(except_fresh$aisle)))
```

_There are **`r num_aisle`** distinct aisles, **`r aisle_most`** and **`r aisle_2most`** are the most items ordered from._

To make a plot that we want, the first step is to manipulate our dataset with conditions. In this condition, we need to `count` how many items are ordered in each aisle and `filter` out how many of them has more than 10000 items ordered. We can call `fct_reorder` from `forcats` package to change the order level according to aisle name and number of orders. Then, we can plot out the number of items ordered in each aisle using `geom_point` with labels and themes being added. Lastly, we just need to save the output plot into a `results` directory using `ggsave`.

```{r plot aisle}
reorder_aisle =
  instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n))

numorder_aisle =
  ggplot(data = reorder_aisle, aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

ggsave("./results/problem_1/aisle_orders.pdf", numorder_aisle, width = 8, height = 5)
numorder_aisle
```

Then we are going to make a table showing the top three popular items in each of “baking ingredients”, “dog food care”, and “packaged vegetables fruits” aisles. The table will include corresponding aisle, product name, number of orders, and rank.

```{r popular table}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

_From the table we can indicate that the top three most popular items for "packaged vegetables fruits" are `Organic Baby Spinach`, `Organic Raspberries`, and `Organic Blueberries`.The top three most popular items for "baking ingredients" are `Light Brown Sugar`, `Pure Baking Soda`, and `Cane Sugar`. The top three most popular items for "dog food care" are `Snack Sticks Chicken & Rice Recipe Dog Treats	`, `Organix Chicken & Brown Rice Recipe`, and `Small Dog Biscuits`._

Next we'll create a table showing the mean hour of orders in each weekday for "Pink Lady Apples" and "Coffee Ice Cream". We can first `filter` and `group by` product name and order dow and then `summarize` the mean order hour for each weekday. Since we want to create a 2*7 table, we can use `pivot_wider` to change the spread of data.

```{r hour table, message = FALSE}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_order_hour = mean(order_hour_of_day)) %>%
  pivot_wider(names_from = "order_dow", values_from = "mean_order_hour") %>%
  knitr::kable(digits = 2)
```

_This result table infers that Pink Lady Apples are generally purchased slightly earlier in the day than Coffee Ice Cream, with the exception of day 5._

# Problem 2

First we need to import, clean and wrangle the `accel_data` dataset. Since the original dataset has 1440 activities listed in wide forma, I would like to use `pivot_longer` to transform these activities with their values into a column format with name equals `activity` and value equals to `activity_count`. Then, we'll need a "weekday vs. weekend" column. We can `mutate` this column using the `case_when` function to determine which days should be considered as "weekday" and which days are "weekend". Since one-minute intervals are common for `activity_minutes`, I'll delete the "activity" prefix and change the class of this variable to `integers`.

```{r import accel}
accel_df =
  read.csv(file = "./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_minutes",
    values_to = "activity_counts",
    names_prefix = "activity_"
  ) %>%
  mutate(
    weekday_vs_weekend = case_when(
      day == "Monday"    ~ "weekday",
      day == "Tuesday"   ~ "weekday",
      day == "Wednesday" ~ "weekday",
      day == "Thursday"  ~ "weekday",
      day == "Friday"    ~ "weekday",
      day == "Saturday"  ~ "weekend",
      day == "Sunday"    ~ "weekend",
      TRUE               ~ ""
    )
  ) %>%
  mutate(activity_minutes = as.integer(activity_minutes))
```

_After manipulating the "accel" dataset, it contains `r nrow(accel_df)` rows and `r ncol(accel_df)` columns, which means that there are `r nrow(accel_df)` observations. We have `week, day_id, day, activity_minutes, activity_counts, weekday_vs_weekend` as variables, where `week, day_id, activity_minutes, activity_counts` are numerical variables and `day, activity, weekday_vs_weekend` in character variables._

Then we want to focus on analyzing total activity over each day. First we need to group our data by variables according to each day, then we need to create a `total_activity` variable to sum up minutes of all activities. With these information, we can generate a table showing totals for each day.s

```{r each day total, message = FALSE}
accel_df %>%
  group_by(week, day_id, day) %>%
  summarize(total_activity = sum(activity_counts)) %>%
  knitr::kable()
```

_In general, the trends of total activity over the day are not apparent, because total activity fluctuates irregularly between days. But we can find some extreme small values on 24th and 31st day, both of them are Saturday._

Lastly we are going to create a single-panel plot showing the correlation between `activity minutes` after midnight and `activity counts` and use color to indicate day of the week.

```{r accel plot}
activity_hour_plot =
  accel_df %>%
    ggplot(aes(x = activity_minutes, y = activity_counts, color = day)) +
    geom_point() +
    labs(
      title = "24-Hour Activity Time Courses For Each Day",
      x = "Time After Midnight (Min)",
      y = "Activity Counts",
      caption = "Data from accel_data"
    )

ggsave("./results/problem_2/activity_hour.pdf", activity_hour_plot, width = 8, height = 5)
activity_hour_plot
```

_We find that for most days in a week, most of the activity counts show a clear upward trend from 6:00 a.m. to 12:00 p.m., among them, activity counts on Thursday and Sunday peaked during this time period. From 12:30 pm to 18:45 pm, activity counts fluctuate in a moderate range for most days, and activity counts on Saturdays and Sundays reach higher increases around 16:40 pm. For Wednesday, Friday, and Saturday, 20:50p.m. is when activity counts fluctuate the most. We can conclude that for most days in a week, activity counts It is basically at a stable minimum value in the early morning, which may be caused by deep sleep. And it will reach its peak twice at noon and at night._